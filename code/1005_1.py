# -*- coding: utf-8 -*-
"""1005-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XLYG60xEC-ImOYdyK6xB3dGV6QWg7dyv
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from tqdm.notebook import tqdm
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from types import SimpleNamespace
from sklearn.preprocessing import MinMaxScaler
import lightgbm as lgb
from sklearn.model_selection import train_test_split
import os

train_df = pd.read_csv('/content/drive/MyDrive/데이터·AI를 활용한 물가 예측 경진대회 : 농산물 가격을 중심으로/train/train.csv')
train_df

train_df.describe()

train_df.nunique()

def filter_data(df):
    # 각 품목에 대한 필터링 조건 정의
    conditions = {
        '건고추': {'품종명': '화건', '거래단위': '30 kg', '등급': '상품'},
        '사과': {'품종명': ['홍로', '후지'], '거래단위': '10 개', '등급': '상품'},
        '감자': {'품종명': '감자 수미', '거래단위': '20키로상자', '등급': '상'},
        '배': {'품종명': '신고', '거래단위': '10 개', '등급': '상품'},
        '깐마늘(국산)': {'품종명': '깐마늘(국산)', '거래단위': '20 kg', '등급': '상품'},
        '무': {'품종명': '무', '거래단위': '20키로상자', '등급': '상'},
        '상추': {'품종명': '청', '거래단위': '100 g', '등급': '상품'},
        '배추': {'품종명': '배추', '거래단위': '10키로망대', '등급': '상'},
        '양파': {'품종명': '양파', '거래단위': '1키로', '등급': '상'},
        '대파': {'품종명': '대파(일반)', '거래단위': '1키로단', '등급': '상'}
    }

    # 조건에 맞는 행만 선택
    mask = pd.Series([False] * len(df))

    for 품목명, 조건 in conditions.items():
        # 각 열이 데이터프레임에 존재하는지 확인하고 필터링 조건 생성
        품종_조건 = df['품종명'].isin(조건['품종명']) if ('품종명' in df.columns and isinstance(조건['품종명'], list)) else (df['품종명'] == 조건['품종명']) if '품종명' in df.columns else True
        품목_조건 = (df['품목명'] == 품목명) if '품목명' in df.columns else True
        거래단위_조건 = (df['거래단위'] == 조건['거래단위']) if '거래단위' in df.columns else True
        등급_조건 = (df['등급'] == 조건['등급']) if '등급' in df.columns else True

        # 각 품목의 조건에 맞는 행만 True로 설정
        mask |= (품목_조건 & 품종_조건 & 거래단위_조건 & 등급_조건)

    return df[mask]

train_df = filter_data(train_df)
train_df

train_df = train_df.drop(columns=['품종명', '거래단위', '등급'])
train_df

# 2. 품목명 임베딩
def embed_variety(df, variety_list):
    # 품목명을 정수 인코딩
    variety_to_index = {variety: idx for idx, variety in enumerate(variety_list)}
    df['품목명_encoded'] = df['품목명'].map(variety_to_index)

    # 임베딩 레이어 정의 (임베딩 차원: 4)
    embedding_dim = 4
    variety_unique_count = len(variety_list)
    embedding_layer = nn.Embedding(variety_unique_count, embedding_dim)

    # 임베딩 벡터를 데이터프레임에 추가
    with torch.no_grad():
        input_tensor = torch.tensor(df['품목명_encoded'].values, dtype=torch.long)
        embedding_vectors = embedding_layer(input_tensor)
        for i in range(embedding_dim):
            df[f'품목명_encoded_{i}'] = embedding_vectors[:, i].numpy()

    # 인코딩 열 제거
    df.drop(columns=['품목명_encoded'], inplace=True)
    return df

variety_list = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추','배추', '양파', '대파']
train_df = embed_variety(train_df, variety_list)
train_df

# 3. 이전 8순, 미래 3순 파생 변수 생성
def create_time_features(df):
    # 이전 8순 파생 변수 생성
    for i in range(1, 9):
        df[f'T-{i}순'] = df['평균가격(원)'].shift(i)

    # 미래 3순 타깃 변수 생성
    df['가격_T+1'] = df['평균가격(원)'].shift(-1)
    df['가격_T+2'] = df['평균가격(원)'].shift(-2)
    df['가격_T+3'] = df['평균가격(원)'].shift(-3)

    # NaN이 포함된 행 제거 (슬라이딩 윈도우의 영향)
    df.dropna(inplace=True)

    return df

train_df = create_time_features(train_df)
train_df

train_df.isna().sum()

# 4. 학습 데이터의 time_idx 생성
def add_time_index(df):
    # 시점 분해: 연도, 월, 순으로 분해
    df['연도'] = df['시점'].str[0:4].astype(int)
    df['월'] = df['시점'].str[4:6].astype(int)
    df['순'] = df['시점'].str[6:].map({'상순': 1, '중순': 2, '하순': 3})

    # 시간 인덱스 생성 (연도와 월을 합쳐 고유한 인덱스 생성)
    df['time_idx'] = (df['연도'] - df['연도'].min()) * 12 * 3 + (df['월'] - 1) * 3 + (df['순'] - 1)
    df = df.drop(columns=['시점', '연도', '월', '순'])

    return df

train_df = add_time_index(train_df)
train_df

# 학습 및 검증 데이터 분리
X = train_df.drop(columns=['가격_T+1', '가격_T+2', '가격_T+3', '품목명'])
y = train_df[['가격_T+1', '가격_T+2', '가격_T+3']]

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=2024)

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import pandas as pd
import numpy as np

# 개별 모델을 학습하여 3순 예측
models = {}
predictions = {}
nmae_scores = {}

for target in ['가격_T+1', '가격_T+2', '가격_T+3']:
    train_data = lgb.Dataset(X_train, label=y_train[target])
    valid_data = lgb.Dataset(X_valid, label=y_valid[target], reference=train_data)

    # 모델 학습
    params = {
        'objective': 'regression',
        'metric': 'mae',
        'boosting_type': 'gbdt',
        'verbose': -1
    }
    model = lgb.train(params, train_data, valid_sets=[valid_data], num_boost_round=100)

    # 모델 저장
    models[target] = model

    # 예측
    predictions[target] = model.predict(X_valid)

    # NMAE 계산
    mae = mean_absolute_error(y_valid[target], predictions[target])
    nmae = mae / np.mean(y_valid[target])
    nmae_scores[target] = nmae

# 평가 리포트 출력
print("\n--- Validation Report ---")
for target, nmae in nmae_scores.items():
    print(f"{target} - NMAE: {nmae:.4f}")

# 전체 평균 NMAE 계산
average_nmae = np.mean(list(nmae_scores.values()))
print(f"\nAverage NMAE across all predictions: {average_nmae:.4f}")

# 마지막 학습 데이터의 time_idx
last_train_idx = train_df['time_idx'].max()

# 5. 테스트 데이터 전처리
def preprocess_test_data(test_df, variety_list, last_train_idx):
    test_df = filter_data(test_df)

    # 품종명 임베딩
    test_df = embed_variety(test_df, variety_list)

    # 이전 8순 파생 변수 생성 (미래 순에 대한 타깃 변수는 생성하지 않음)
    for i in range(1, 9):
        test_df[f'T-{i}순'] = test_df['평균가격(원)'].shift(i)

    # NaN이 포함된 행 제거 (슬라이딩 윈도우의 영향)
    test_df.dropna(inplace=True)

    # 시점 맵핑: T-8순 -> test_df + 1, ..., T -> test_df + 9
    time_mapping = {f'T-{i}순': last_train_idx + (i + 1) for i in range(8, 0, -1)}
    time_mapping['T'] = last_train_idx + 9
    test_df['time_idx'] = test_df['시점'].map(time_mapping)

    # 필요 없는 열 제거
    test_df.drop(columns=['시점', '품종명', '거래단위', '등급'], inplace=True)
    return test_df

# Google Drive 경로 설정
test_data_path = '/content/drive/MyDrive/데이터·AI를 활용한 물가 예측 경진대회 : 농산물 가격을 중심으로/test/'

test00 = pd.read_csv('/content/drive/MyDrive/데이터·AI를 활용한 물가 예측 경진대회 : 농산물 가격을 중심으로/test/TEST_00.csv')
test00

test00 = preprocess_test_data(test00, variety_list, last_train_idx)
test00

import glob

# 테스트 데이터 예측을 저장할 리스트
test_predictions = []

# 품목명 리스트 (제출 파일의 열 순서를 맞추기 위함)
items = ['감자', '건고추', '깐마늘(국산)', '대파', '무', '배추', '사과', '상추', '양파', '배']

# TEST_00.csv ~ TEST_24.csv 파일을 읽어 예측 수행
for test_file in sorted(glob.glob(f'{test_data_path}/TEST_*.csv')):  # 경로는 실제 데이터가 있는 경로로 변경
    # 테스트 데이터 로드
    test_df = pd.read_csv(test_file)

    # 테스트 데이터 전처리
    test_df = preprocess_test_data(test_df, variety_list, last_train_idx)

    # 필요한 피처 추출 (예: T-8순 ~ T-1순까지 포함한 전체 피처 사용)
    X_test = test_df.drop(columns=['품목명'])
    test_varieties = test_df['품목명'].values  # 품목명 추출

    # 개별 타깃에 대해 예측 수행
    prediction = {}
    for target in ['가격_T+1', '가격_T+2', '가격_T+3']:
        model = models[target]  # 학습한 모델 불러오기
        prediction[target] = model.predict(X_test)

    # 결과를 데이터프레임으로 정리
    test_idx = test_file.split('/')[-1].replace('.csv', '')  # 파일명에서 TEST_00, TEST_01 등을 추출
    for step in range(1, 4):  # +1순, +2순, +3순
        row_data = {'시점': f'{test_idx}+{step}순'}
        for item in items:
            # 해당 품목에 대한 예측 값이 있으면 저장, 없으면 0.0으로 설정
            if item in test_varieties:
                idx = np.where(test_varieties == item)[0][0]
                row_data[item] = prediction[f'가격_T+{step}'][idx]
            else:
                row_data[item] = 0.0
        test_predictions.append(row_data)

# 최종 제출 파일 생성
submission_df = pd.DataFrame(test_predictions)

submission_df

# 제출 파일 저장
submission_path = '/content/drive/MyDrive/데이터·AI를 활용한 물가 예측 경진대회 : 농산물 가격을 중심으로/submission.csv'
submission_df.to_csv(submission_path, index=False)

# 1.46852